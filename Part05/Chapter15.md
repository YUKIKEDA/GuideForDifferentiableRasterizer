# 第15章 GPU 実装の基礎

第 14 章で微分可能ラスタライザのコアを Python で組み立てました。本章では **GPU 実装の基礎** を扱います。CUDA / Metal の基本（カーネル・メモリ）（15.1）、並列ラスタライゼーションの設計（三角形並列 vs ピクセル並列）（15.2）、アトミック操作と深度ソート（15.3）、フレームワークとの連携（PyTorch C++ extension, custom op）（15.4）、プロファイリングと最適化（15.5）、そして C++ / CUDA 拡張のビルドエコシステム（15.6）を学びます。実用レベルのライブラリでは環境構築・ビルドが最大の障壁になりがちなので、15.6 ではその対処の考え方も整理します。

---

## 15.1 CUDA / Metal の基本（カーネル・メモリ）

### 15.1.1 GPU 並列の考え方

GPU は **多数のスレッド** を同時に実行し、メモリ帯域を活かして並列性で性能を出します。各スレッドは **カーネル**（GPU 上で動く関数）の 1 インスタンスです。

- **CUDA（NVIDIA）**: スレッドは **block** 内にまとまり、block の集合が **grid**。`blockIdx`, `threadIdx` でスレッドを一意に特定。共有メモリ（block 内で共有）とグローバルメモリ（全スレッドから参照）を使い分ける。
- **Metal（Apple）**: **threadgroup** と **thread position** で同様の階層。Metal Shading Language でカーネルを書く。

本教材では主に **CUDA** を例にしますが、並列の設計（「何を並列にするか」）は Metal でも共通です。

### 15.1.2 カーネルの起動

CUDA では、ホスト（CPU）から `kernel<<<grid, block>>>(args)` のようにカーネルを起動します。  
例: 解像度 $W \times H$ のピクセルを処理するとき、各ピクセルに 1 スレッドを割り当てるなら、block を $(16, 16)$、grid を $(\lceil W/16 \rceil, \lceil H/16 \rceil)$ とする、といった形です。スレッド数が多すぎるとリソース制限に当たるため、block あたりのスレッド数（例: 256〜1024）と grid の次元の上限を意識します。

### 15.1.3 メモリの種類とアクセスパターン

- **グローバルメモリ**: デバイス上の主記憶。帯域は有限で、**連続アクセス**（coalesced access）にすると効率が良い。ラスタライザでは、頂点バッファ・面インデックス・フレームバッファ・深度バッファがここに載る。
- **共有メモリ**: block 内のスレッドで共有。グローバルより速い。同一 block 内で同じ三角形やタイルのデータをキャッシュするのに使う。
- **レジスタ**: スレッドごとの局所変数。最も速い。中間計算はできるだけレジスタに置く。

ラスタライゼーションでは、「どのスレッドがどの三角形／どのピクセルを担当するか」を決め、メモリへの読み書きが **なるべく連続・局所** になるように設計します（15.2）。

### 15.1.4 ホストとデバイス間の転送

CPU 側（ホスト）と GPU 側（デバイス）の間でデータをコピーするには、`cudaMemcpy` などを使います。転送は遅いため、**最小限の転送** に抑え、計算は GPU 上で完結させるのが基本です。PyTorch ではテンソルがすでに GPU 上にあれば、custom op にポインタを渡すだけで転送を避けられます。

---

## 15.2 並列ラスタライゼーション（三角形並列 vs ピクセル並列）

### 15.2.1 三角形並列（Triangle-Parallel）

**三角形並列** では、各スレッド（または block）が **1 つ以上の三角形** を担当します。

- スレッド $t$ は三角形 $t$ を受け取り、その三角形がカバーする **ピクセル** を走査（バウンディングボックス内など）し、エッジ関数・重心座標・深度を計算してフレームバッファ・深度バッファに書き込む。
- **利点**: 三角形ごとの独立性が高く、実装が直感的。頂点データの読み込みも三角形単位でまとまりやすい。
- **課題**: 複数三角形が **同じピクセル** に書き込むため、**深度テスト** と **フレームバッファへの書き込み** で競合が起きる。アトミック操作や深度ソート（15.3）で解決する。

多くの GPU ラスタライザは、何らかの形で「三角形単位の並列」をベースにし、ピクセルへの書き込みの競合をどう扱うかが設計の中心になります。

### 15.2.2 ピクセル並列（Pixel-Parallel）

**ピクセル並列** では、各スレッドが **1 ピクセル** を担当します。

- スレッド $(i,j)$ はピクセル $(i,j)$ について、**すべての三角形**（またはタイルに含まれる三角形）を調べ、そのピクセルに寄与する三角形を選び、色・深度を計算する。
- **利点**: フレームバッファ・深度バッファへの書き込みは **1 スレッド 1 ピクセル** なので、競合がなく、深度テストもそのスレッド内で完結する。
- **課題**: 1 ピクセルが多くの三角形を参照するため、三角形数が大きいと「どの三角形がこのピクセルを覆うか」の探索コストが増える。**タイルベース** で「このタイルに含まれる三角形だけ」に限定すると現実的になる。

ハイブリッドとして、「タイル単位で三角形を割り当て、タイル内ではピクセル並列」という形もよく使われます（タイルベースラスタライザ）。

### 15.2.3 トレードオフと選択

| 方式 | 書き込み競合 | 探索コスト | 実装のしやすさ |
|------|--------------|------------|----------------|
| 三角形並列 | あり（アトミック等で対処） | 小さい | 直感的 |
| ピクセル並列 | なし | 三角形数に依存（タイルで軽減） | 探索・ソートが必要 |

微分可能ラスタライザでは、**逆伝播** で「どのピクセルにどの三角形が描かれたか」と「重心座標」が必要なので、順伝播でそれらを一貫して保存する設計にします。nvdiffrast は三角形並列をベースに、深度ソートやバッファレイアウトで効率を出しています（Part VI）。

---

## 15.3 アトミック操作と深度ソート

### 15.3.1 書き込み競合の問題

三角形並列では、複数スレッドが **同じピクセル** に色・深度を書き込む可能性があります。通常の書き込みでは、後から書いた値が前の値を上書きするだけで、**どちらが手前か** の判定ができません。そのため、**深度テスト** と **手前のものだけ残す** 処理を、並列でも正しく行う必要があります。

### 15.3.2 アトミック操作

**アトミック操作** は、複数スレッドが同じメモリ位置を更新するとき、**不可分** に 1 つの更新だけが反映されるようにする仕組みです。

- **atomicMin / atomicMax**: 深度バッファで「より手前の深度だけを残す」ために、現在値と新しい深度を比較し、条件を満たすときだけ書き込む、といった用途。CUDA では `atomicMin` で深度の更新ができるが、**色** は単一のスカラーではないため、深度だけアトミックにして、色は別の方法（後述）で決めることが多い。
- **深度＋色の一貫性**: 深度をアトミックで更新する場合、「どの三角形の色を書くか」を深度と一致させる必要がある。一つの方法は、**深度バッファをアトミックで更新** し、**色は「深度が更新されたときだけ」書き込む**（compare-and-swap 的な流れ）。別の方法は、いったん **フラグメントをリストに蓄積** し、あとでソートしてから 1 スレッドで書き込む。

### 15.3.3 深度ソート（Per-Pixel Linked List 等）

**深度ソート** では、各ピクセルに **複数三角形のフラグメント**（深度・色・三角形 ID・重心座標など）をいったん蓄積し、あとで **深度順にソート** して、手前の 1 つ（または数個）だけを採用します。

- **Per-Pixel Linked List**: ピクセルごとにフラグメントのリンクリストを持ち、三角形並列でリストに追加（アトミックで next ポインタを更新）。その後、ピクセル並列で各リストを走査し、深度でソートしてから色を決める。
- **A-buffer 的**: ピクセルあたりのフラグメント数を上限で切り、配列に格納。三角形並列でアトミックに「空きスロット」を取得して書き込み、のちにピクセル並列でソート。

微分可能ラスタライザでは、**どの三角形が手前だったか** と **その重心座標** を逆伝播で使うため、順伝播で「手前の三角形 ID・重心座標・深度」を保存しておく必要があります。深度ソートで手前を決めたあと、その情報を幾何バッファに書き込む形にします。

### 15.3.4 実装の現実性

フルな A-buffer はメモリと複雑さが増すため、**少ない三角形数** や **タイル内でソート** に限定する、あるいは **ソフトラスタ** のように深度のソフトマックスで連続化し、アトミックに頼らない設計にする、といったトレードオフがあります。nvdiffrast では、三角形の並列処理と、ピクセルごとの「勝者」の決定を効率化するための内部バッファ設計がされています（Part VI）。

---

## 15.4 フレームワークとの連携（PyTorch C++ extension, custom op）

### 15.4.1 なぜ C++ / CUDA 拡張か

Python だけでは、ピクセルごと・三角形ごとの細かいループが **GIL** とインタプリタのオーバーヘッドで遅くなります。**C++** でループを書き、**CUDA** で GPU カーネルを書くと、PyTorch のテンソルと連携しつつ、十分な速度を出せます。PyTorch は **C++ extension** と **CUDA カーネル** を組み合わせた **custom op** を公式にサポートしています。

### 15.4.2 PyTorch C++ extension の流れ

1. **C++ で forward / backward を実装**: `torch::Tensor` を受け取り、CPU または CUDA で計算し、`torch::Tensor` を返す。backward では `torch::autograd::Function` を継承したクラスで `forward` と `backward` を定義する。
2. **CUDA カーネル**: `.cu` ファイルに `__global__` カーネルを書き、C++ 側から `kernel<<<grid, block>>>(...)` で呼び出す。テンソルのデータは `tensor.data_ptr<T>()` でポインタ取得（device が一致していることを前提）。
3. **Python から呼び出し**: `torch.ops.load_library(...)` や `setuptools` でビルドした拡張を `import` し、`torch.ops.my_module.my_op(...)` のように呼ぶ。`torch.autograd.Function` でラップして `forward`/`backward` から C++ を呼んでもよい。

これにより、第 14 章の Python 実装を、**同じ入出力仕様** の C++/CUDA 版に差し替えられます。

### 15.4.3 テンソルとデバイス

- **連続性**: PyTorch のテンソルはメモリ上で連続であることが多いが、`.contiguous()` で保証できる。C++ に渡す前に `contiguous()` を呼んでおくと安全。
- **デバイス**: CUDA カーネルを呼ぶときは、入力テンソルが `.is_cuda` であることを確認し、同じ device のポインタを渡す。CPU フォールバックを書く場合は、device に応じて分岐する。
- **勾配**: backward で返すテンソルは、入力と同じ device・dtype・shape にする。勾配が不要な入力には `nullptr` や空テンソルを返す。

---

## 15.5 プロファイリングと最適化

### 15.5.1 ボトルネック特定

- **CUDA のプロファイラー**: `nvprof` や **NVIDIA Nsight Systems / Compute** で、カーネルごとの実行時間やメモリ使用量を計測する。どのカーネルが支配的か、メモリ転送が遅くないかを確認する。
- **PyTorch**: `torch.profiler` で Python 側のオペレーションと CUDA カーネルをまとめて見る。custom op がどの程度時間を食っているかが分かる。
- **段階的計測**: まず「MVP だけ GPU」「ラスタライズだけ GPU」のように区切り、どこで時間が増えるかを特定する。

### 15.5.2 メモリバンド幅 vs 計算バウンド

- **メモリバウンド**: 演算量より **メモリの読み書き量** が性能を決める場合。ラスタライザでは、頂点・面・フレームバッファ・深度バッファへのアクセスが該当する。対策は、** coalesced アクセス**、**共有メモリでの再利用**、**キャッシュを意識したレイアウト**。
- **計算バウンド**: 演算量が多く、メモリは比較的余裕がある場合。エッジ関数・重心座標・補間の計算が該当。対策は、**無駄な計算の削減**、**レジスタ圧力とのバランス**。

多くのラスタライザは **メモリバウンド** に近いため、メモリアクセスパターンの最適化が効きやすいです。プロファイラで「achieved occupancy」や「memory throughput」を見て、ボトルネックを判断します。

### 15.5.3 最適化の優先度

1. **正しさ**: 勾配チェックと結果の一致を最優先。
2. **メモリレイアウト**: 連続アクセス、必要なら SoA（Struct of Arrays）でキャッシュを有効に。
3. **並列度**: block / grid のサイズ、occupancy。過度に大きくしすぎない。
4. **共有メモリ**: 同じ三角形やタイルのデータを block で共有してグローバルメモリアクセスを減らす。

---

## 15.6 C++ / CUDA 拡張のビルドエコシステム（システム・エンジニアリング）

### 15.6.1 setuptools・setup.py・ninja のベストプラクティス

PyTorch の C++ extension は、**setuptools** と **setup.py**（または `pyproject.toml`）でビルドします。

- **Extension の定義**: `torch.utils.cpp_extension.CUDAExtension` で、ソースファイル（`.cpp`, `.cu`）とインクルードパス・コンパイルフラグを指定する。
- **ninja**: `ninja` をビルドバックエンドにすると、増分ビルドが速い。`setup.py` で `cmdclass={'build_ext': torch.utils.cpp_extension.BuildExtension}` を使うと、PyTorch が推奨するフラグと ninja が使われる。
- **CUDA のバージョン**: 環境の CUDA と、PyTorch がビルドされた CUDA バージョンを揃える。`torch.version.cuda` で確認できる。違うとリンクエラーや実行時エラーの原因になる。
- **インクルード**: PyTorch のインクルードパス（`torch.utils.cpp_extension.include_paths()`）と CUDA のインクルードを正しく渡す。

公式ドキュメントの「Custom C++ and CUDA Extensions」に、最小の `setup.py` 例があります。それをベースに、自分のプロジェクトのソースツリーに合わせてパスを調整します。

### 15.6.2 JIT コンパイル（load_inline）vs AOT（事前）コンパイル

- **JIT（Just-In-Time）**: `torch.utils.cpp_extension.load_inline` で、C++ / CUDA の**文字列**を渡し、その場でコンパイルしてロードする。手軽だが、毎回コンパイルが走るため初回が遅く、複雑なプロジェクトには向かない。プロトタイプや小さなカーネルの試行に向く。
- **AOT（Ahead-of-Time）**: `setup.py` で拡張をビルドし、`pip install -e .` や `python setup.py build develop` でインストールする。一度ビルドすれば、import 時にロードするだけ。**実用ライブラリ** はほぼこちら。CI でビルドして wheel を配布する場合も AOT。

本教材で nvdiffrast 相当を目指すなら、**AOT** で拡張をビルドし、`setup.py` とビルド環境を整える流れが現実的です。

### 15.6.3 実用ライブラリを作る上での最大の障壁となる環境構築・ビルド

- **環境の多様性**: ユーザーごとに OS・CUDA バージョン・Python バージョン・コンパイラが異なる。**多くの環境でビルドが通る** ようにするには、CMake や setuptools の条件分岐、CI でのマトリックスビルド（複数 CUDA・複数 Python）がほぼ必須。
- **エラーメッセージ**: コンパイルエラーやリンクエラーは、CUDA や PyTorch のヘッダ不足・バージョン不一致で起きやすい。**README に必要な環境**（CUDA バージョン、Python、PyTorch バージョン）を明記し、**よくある失敗と対処** を書いておくと運用しやすい。
- **manylinux / wheel**: 配布用に Linux で wheel をビルドする場合、manylinux 規約に合わせた Docker イメージでビルドする方法が一般的。CUDA 付きのイメージは NVIDIA が提供している。
- **フォールバック**: CUDA が使えない環境では、**CPU 版の拡張だけ** をビルドする、または **Pure Python の実装**（第 14 章）にフォールバックする、といった選択肢を用意すると、ユーザーの環境で動く確率が上がる。

「実用ライブラリを作る上での最大の障壁」は、**アルゴリズムより環境構築・ビルド** であることが多いです。時間を割いて、README・CI・バージョン表を整えておくことを推奨します。

---

## 15.7 まとめと次章への接続

- **CUDA / Metal の基本**: カーネル・grid/block・グローバル/共有メモリ、連続アクセスとメモリ帯域の意識。ホスト・デバイス間の転送を最小に。
- **並列ラスタライゼーション**: 三角形並列は直感的だが書き込み競合があり、ピクセル並列は競合がないが探索コストがある。タイルベースやハイブリッドが現実的。
- **アトミックと深度ソート**: 同一ピクセルへの複数書き込みは、アトミック操作やフラグメントの蓄積＋深度ソートで解決。微分可能では「手前の三角形 ID・重心座標」の保存が逆伝播に必要。
- **フレームワーク連携**: PyTorch C++ extension で forward/backward を C++/CUDA に実装し、Python から custom op として呼ぶ。テンソルの device・連続性・勾配の形に注意。
- **プロファイリング**: ボトルネックの特定、メモリバウンド vs 計算バウンドの見極め、メモリアクセスと並列度の最適化。
- **ビルドエコシステム**: setuptools・ninja・CUDA バージョン揃え。JIT は試行向け、AOT は実用向け。環境構築・ビルドが実用化の最大の障壁になり得ることを認識し、README・CI・フォールバックを整える。

次章（第 16 章）では **本格的なパイプライン** に進み、メッシュ入力・バッチ処理・マルチ解像度、テクスチャサンプリングの微分可能実装、アンチエイリアシングの組み込み、半透明・ブレンディング、そして nvdiffrast とのテスト・ベンチマークを学びます。本章の GPU 基礎とビルドを土台に、完成度の高いパイプラインを目指します。

---

*前: [第 14 章 微分可能ラスタライザのコア](Chapter14.md) | 次: [第 16 章 本格的なパイプライン](Chapter16.md)*
